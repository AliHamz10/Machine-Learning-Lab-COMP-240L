{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lab 03: Insurance Dataset Linear Regression Analysis\n",
        "\n",
        "**Department of Electrical and Computer Engineering**  \n",
        "**Pak-Austria Fachhochschule: Institute of Applied Sciences & Technology**  \n",
        "**Subject: Machine Learning**  \n",
        "**Subject Teacher: Dr. Abid Ali**  \n",
        "**Lab Supervisor: Miss. Sana Saleem**\n",
        "\n",
        "## Lab Tasks Objectives\n",
        "1. Implement linear regression to predict insurance charges using a real-world dataset\n",
        "2. Explore and preprocess datasets, including handling missing values and outliers\n",
        "3. Apply data visualization techniques to understand data distributions and correlations\n",
        "4. Train and evaluate a linear regression model using performance metrics\n",
        "5. Use gradient descent to optimize model parameters and understand the cost function\n",
        "6. Analyze model performance using metrics such as accuracy, precision, recall, and F1-score\n",
        "7. Visualize the importance of features in the model and analyze training loss over time\n",
        "\n",
        "## Dataset\n",
        "- **File**: Insurance.csv\n",
        "- **Features**: age, gender, bmi, children, smoker, region\n",
        "- **Target Variable**: charges (medical insurance charges)\n",
        "- **Total Records**: 1,338\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import all necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import (mean_squared_error, r2_score, mean_absolute_error,\n",
        "                           accuracy_score, precision_score, recall_score, f1_score,\n",
        "                           confusion_matrix, roc_curve, auc, precision_recall_curve)\n",
        "from scipy import stats\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set plotting style\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"Set2\")\n",
        "\n",
        "print(\"All libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 1: Data Loading and Exploration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the insurance dataset\n",
        "df = pd.read_csv('Insurance.csv')\n",
        "\n",
        "print(\"INSURANCE DATASET ANALYSIS\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"Dataset shape: {df.shape}\")\n",
        "print(f\"Features: {list(df.columns)}\")\n",
        "print(f\"Data types:\\n{df.dtypes}\")\n",
        "\n",
        "print(\"\\nFirst 5 rows:\")\n",
        "print(df.head())\n",
        "\n",
        "print(\"\\nDataset Statistics:\")\n",
        "print(df.describe())\n",
        "\n",
        "print(\"\\nMissing Values:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "print(f\"\\nMissing Values Percentage:\")\n",
        "print((df.isnull().sum() / len(df)) * 100)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 2: Data Visualization and Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Comprehensive data visualization\n",
        "fig = plt.figure(figsize=(20, 16))\n",
        "\n",
        "# 1. Target variable distribution\n",
        "plt.subplot(4, 4, 1)\n",
        "plt.hist(df['charges'], bins=30, alpha=0.7, color='steelblue', edgecolor='black')\n",
        "plt.title('Distribution of Insurance Charges')\n",
        "plt.xlabel('Charges ($)')\n",
        "plt.ylabel('Frequency')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# 2. Log-transformed charges\n",
        "plt.subplot(4, 4, 2)\n",
        "plt.hist(np.log(df['charges']), bins=30, alpha=0.7, color='crimson', edgecolor='black')\n",
        "plt.title('Log-Transformed Charges')\n",
        "plt.xlabel('Log(Charges)')\n",
        "plt.ylabel('Frequency')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# 3. Age distribution\n",
        "plt.subplot(4, 4, 3)\n",
        "plt.hist(df['age'], bins=20, alpha=0.7, color='skyblue', edgecolor='black')\n",
        "plt.title('Age Distribution')\n",
        "plt.xlabel('Age')\n",
        "plt.ylabel('Frequency')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# 4. BMI distribution\n",
        "plt.subplot(4, 4, 4)\n",
        "plt.hist(df['bmi'], bins=20, alpha=0.7, color='lightgreen', edgecolor='black')\n",
        "plt.title('BMI Distribution')\n",
        "plt.xlabel('BMI')\n",
        "plt.ylabel('Frequency')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# 5. Gender distribution\n",
        "plt.subplot(4, 4, 5)\n",
        "gender_counts = df['gender'].value_counts()\n",
        "plt.pie(gender_counts.values, labels=gender_counts.index, autopct='%1.1f%%', \n",
        "        colors=['lightcoral', 'lightblue'], startangle=90)\n",
        "plt.title('Gender Distribution')\n",
        "\n",
        "# 6. Smoking status\n",
        "plt.subplot(4, 4, 6)\n",
        "smoker_counts = df['smoker'].value_counts()\n",
        "plt.bar(smoker_counts.index, smoker_counts.values, color=['lightgreen', 'salmon'])\n",
        "plt.title('Smoking Status Distribution')\n",
        "plt.xlabel('Smoking Status')\n",
        "plt.ylabel('Count')\n",
        "\n",
        "# 7. Region distribution\n",
        "plt.subplot(4, 4, 7)\n",
        "region_counts = df['region'].value_counts()\n",
        "plt.bar(region_counts.index, region_counts.values, color='lightsteelblue')\n",
        "plt.title('Geographic Region Distribution')\n",
        "plt.xlabel('Region')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "# 8. Children distribution\n",
        "plt.subplot(4, 4, 8)\n",
        "children_counts = df['children'].value_counts().sort_index()\n",
        "plt.bar(children_counts.index, children_counts.values, color='gold')\n",
        "plt.title('Number of Children Distribution')\n",
        "plt.xlabel('Number of Children')\n",
        "plt.ylabel('Count')\n",
        "\n",
        "# 9. Age vs Charges\n",
        "plt.subplot(4, 4, 9)\n",
        "plt.scatter(df['age'], df['charges'], alpha=0.6, color='forestgreen')\n",
        "plt.title('Age vs Insurance Charges')\n",
        "plt.xlabel('Age')\n",
        "plt.ylabel('Charges ($)')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# 10. BMI vs Charges\n",
        "plt.subplot(4, 4, 10)\n",
        "plt.scatter(df['bmi'], df['charges'], alpha=0.6, color='purple')\n",
        "plt.title('BMI vs Insurance Charges')\n",
        "plt.xlabel('BMI')\n",
        "plt.ylabel('Charges ($)')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# 11. Charges by Smoking Status\n",
        "plt.subplot(4, 4, 11)\n",
        "df.boxplot(column='charges', by='smoker', ax=plt.gca())\n",
        "plt.title('Charges Distribution by Smoking Status')\n",
        "plt.suptitle('')\n",
        "plt.xlabel('Smoking Status')\n",
        "plt.ylabel('Charges ($)')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# 12. Charges by Gender\n",
        "plt.subplot(4, 4, 12)\n",
        "df.boxplot(column='charges', by='gender', ax=plt.gca())\n",
        "plt.title('Charges Distribution by Gender')\n",
        "plt.suptitle('')\n",
        "plt.xlabel('Gender')\n",
        "plt.ylabel('Charges ($)')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# 13. Correlation heatmap\n",
        "plt.subplot(4, 4, 13)\n",
        "# Encode categorical variables for correlation\n",
        "df_corr = df.copy()\n",
        "le_gender = LabelEncoder()\n",
        "le_smoker = LabelEncoder()\n",
        "le_region = LabelEncoder()\n",
        "\n",
        "df_corr['gender_encoded'] = le_gender.fit_transform(df_corr['gender'])\n",
        "df_corr['smoker_encoded'] = le_smoker.fit_transform(df_corr['smoker'])\n",
        "df_corr['region_encoded'] = le_region.fit_transform(df_corr['region'])\n",
        "\n",
        "numerical_cols = ['age', 'bmi', 'children', 'gender_encoded', 'smoker_encoded', 'region_encoded', 'charges']\n",
        "correlation_matrix = df_corr[numerical_cols].corr()\n",
        "\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
        "            square=True, fmt='.2f', cbar_kws={'shrink': 0.8})\n",
        "plt.title('Correlation Matrix')\n",
        "\n",
        "# 14. Charges by Region\n",
        "plt.subplot(4, 4, 14)\n",
        "df.boxplot(column='charges', by='region', ax=plt.gca())\n",
        "plt.title('Charges Distribution by Region')\n",
        "plt.suptitle('')\n",
        "plt.xlabel('Region')\n",
        "plt.ylabel('Charges ($)')\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# 15. Children vs Charges\n",
        "plt.subplot(4, 4, 15)\n",
        "df.boxplot(column='charges', by='children', ax=plt.gca())\n",
        "plt.title('Charges Distribution by Number of Children')\n",
        "plt.suptitle('')\n",
        "plt.xlabel('Number of Children')\n",
        "plt.ylabel('Charges ($)')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# 16. 3D scatter plot (Age, BMI, Charges)\n",
        "plt.subplot(4, 4, 16)\n",
        "ax = plt.gca()\n",
        "scatter = ax.scatter(df['age'], df['bmi'], c=df['charges'], cmap='viridis', alpha=0.6)\n",
        "plt.colorbar(scatter, label='Charges ($)')\n",
        "plt.xlabel('Age')\n",
        "plt.ylabel('BMI')\n",
        "plt.title('Age vs BMI (colored by Charges)')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Statistical summary\n",
        "print(\"\\nCHARGES STATISTICAL SUMMARY\")\n",
        "print(\"=\" * 40)\n",
        "print(f\"Mean: ${df['charges'].mean():.2f}\")\n",
        "print(f\"Median: ${df['charges'].median():.2f}\")\n",
        "print(f\"Standard Deviation: ${df['charges'].std():.2f}\")\n",
        "print(f\"Minimum: ${df['charges'].min():.2f}\")\n",
        "print(f\"Maximum: ${df['charges'].max():.2f}\")\n",
        "print(f\"Skewness: {df['charges'].skew():.3f}\")\n",
        "print(f\"Kurtosis: {df['charges'].kurtosis():.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 3: Data Preprocessing and Feature Engineering\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data preprocessing and feature engineering\n",
        "print(\"DATA PREPROCESSING\")\n",
        "print(\"=\" * 30)\n",
        "\n",
        "# Check for missing values\n",
        "print(\"Missing values check:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Handle categorical variables using Label Encoding\n",
        "le_gender = LabelEncoder()\n",
        "le_smoker = LabelEncoder()\n",
        "le_region = LabelEncoder()\n",
        "\n",
        "df_processed = df.copy()\n",
        "df_processed['gender_encoded'] = le_gender.fit_transform(df_processed['gender'])\n",
        "df_processed['smoker_encoded'] = le_smoker.fit_transform(df_processed['smoker'])\n",
        "df_processed['region_encoded'] = le_region.fit_transform(df_processed['region'])\n",
        "\n",
        "print(f\"\\nCategorical encoding completed:\")\n",
        "print(f\"Gender mapping: {dict(zip(le_gender.classes_, le_gender.transform(le_gender.classes_)))}\")\n",
        "print(f\"Smoker mapping: {dict(zip(le_smoker.classes_, le_smoker.transform(le_smoker.classes_)))}\")\n",
        "print(f\"Region mapping: {dict(zip(le_region.classes_, le_region.transform(le_region.classes_)))}\")\n",
        "\n",
        "# Outlier detection using Z-score\n",
        "numerical_cols = ['age', 'bmi', 'children', 'charges']\n",
        "z_scores = np.abs(stats.zscore(df_processed[numerical_cols]))\n",
        "outlier_indices = np.where(z_scores > 3)\n",
        "print(f\"\\nOutlier analysis:\")\n",
        "print(f\"Number of outliers: {len(outlier_indices[0])}\")\n",
        "\n",
        "# Remove outliers\n",
        "df_clean = df_processed[(z_scores < 3).all(axis=1)]\n",
        "print(f\"Dataset shape after outlier removal: {df_clean.shape}\")\n",
        "\n",
        "# Prepare features and target\n",
        "feature_cols = ['age', 'bmi', 'children', 'gender_encoded', 'smoker_encoded', 'region_encoded']\n",
        "X = df_clean[feature_cols]\n",
        "y = df_clean['charges']\n",
        "\n",
        "print(f\"\\nFeature matrix shape: {X.shape}\")\n",
        "print(f\"Target vector shape: {y.shape}\")\n",
        "print(f\"Feature names: {feature_cols}\")\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(f\"\\nScaled training set shape: {X_train_scaled.shape}\")\n",
        "print(f\"Scaled test set shape: {X_test_scaled.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 4: Linear Regression Model Implementation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Linear Regression Model Implementation\n",
        "print(\"LINEAR REGRESSION MODEL TRAINING\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "# Train the Linear Regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "print(\"Model trained successfully!\")\n",
        "print(f\"Model intercept: ${model.intercept_:.2f}\")\n",
        "print(f\"Number of features: {len(model.coef_)}\")\n",
        "\n",
        "# Display feature coefficients\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': feature_cols,\n",
        "    'Coefficient': model.coef_\n",
        "}).sort_values('Coefficient', key=abs, ascending=False)\n",
        "\n",
        "print(\"\\nFeature Coefficients (sorted by absolute value):\")\n",
        "print(feature_importance)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_train = model.predict(X_train_scaled)\n",
        "y_pred_test = model.predict(X_test_scaled)\n",
        "\n",
        "# Calculate regression metrics\n",
        "mse_train = mean_squared_error(y_train, y_pred_train)\n",
        "mse_test = mean_squared_error(y_test, y_pred_test)\n",
        "r2_train = r2_score(y_train, y_pred_train)\n",
        "r2_test = r2_score(y_test, y_pred_test)\n",
        "mae_train = mean_absolute_error(y_train, y_pred_train)\n",
        "mae_test = mean_absolute_error(y_test, y_pred_test)\n",
        "\n",
        "print(f\"\\nModel Performance:\")\n",
        "print(f\"Training MSE: ${mse_train:.2f}\")\n",
        "print(f\"Test MSE: ${mse_test:.2f}\")\n",
        "print(f\"Training R²: {r2_train:.4f}\")\n",
        "print(f\"Test R²: {r2_test:.4f}\")\n",
        "print(f\"Training MAE: ${mae_train:.2f}\")\n",
        "print(f\"Test MAE: ${mae_test:.2f}\")\n",
        "\n",
        "# Calculate RMSE\n",
        "rmse_train = np.sqrt(mse_train)\n",
        "rmse_test = np.sqrt(mse_test)\n",
        "print(f\"Training RMSE: ${rmse_train:.2f}\")\n",
        "print(f\"Test RMSE: ${rmse_test:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 5: Gradient Descent Implementation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Gradient Descent Implementation\n",
        "print(\"GRADIENT DESCENT IMPLEMENTATION\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "# Initialize parameters\n",
        "np.random.seed(42)\n",
        "m, n = X_train_scaled.shape\n",
        "theta = np.random.randn(n)  # Initial weights\n",
        "bias = 0.0  # Initial bias\n",
        "learning_rate = 0.01\n",
        "epochs = 1000\n",
        "\n",
        "print(f\"Initial parameters:\")\n",
        "print(f\"Theta shape: {theta.shape}\")\n",
        "print(f\"Learning rate: {learning_rate}\")\n",
        "print(f\"Number of epochs: {epochs}\")\n",
        "\n",
        "# Define the cost function (MSE)\n",
        "def compute_cost(X, y, theta, bias):\n",
        "    \"\"\"Compute the mean squared error cost function\"\"\"\n",
        "    m = len(y)\n",
        "    predictions = np.dot(X, theta) + bias\n",
        "    cost = (1 / (2 * m)) * np.sum((predictions - y) ** 2)\n",
        "    return cost\n",
        "\n",
        "# Define gradient descent function\n",
        "def gradient_descent(X, y, theta, bias, learning_rate, epochs):\n",
        "    \"\"\"Perform gradient descent optimization\"\"\"\n",
        "    m = len(y)\n",
        "    cost_history = []\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        # Make predictions\n",
        "        predictions = np.dot(X, theta) + bias\n",
        "        \n",
        "        # Compute gradients\n",
        "        d_theta = (1 / m) * np.dot(X.T, (predictions - y))\n",
        "        d_bias = (1 / m) * np.sum(predictions - y)\n",
        "        \n",
        "        # Update weights\n",
        "        theta -= learning_rate * d_theta\n",
        "        bias -= learning_rate * d_bias\n",
        "        \n",
        "        # Calculate cost and save it for plotting\n",
        "        cost = compute_cost(X, y, theta, bias)\n",
        "        cost_history.append(cost)\n",
        "        \n",
        "        # Print progress every 200 epochs\n",
        "        if epoch % 200 == 0:\n",
        "            print(f\"Epoch {epoch}: Cost = ${cost:.2f}\")\n",
        "    \n",
        "    return theta, bias, cost_history\n",
        "\n",
        "print(\"\\nStarting Gradient Descent Optimization...\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Run gradient descent\n",
        "theta_gd, bias_gd, cost_history = gradient_descent(X_train_scaled, y_train, theta, bias, learning_rate, epochs)\n",
        "\n",
        "print(f\"\\nGradient Descent Completed!\")\n",
        "print(f\"Final theta: {theta_gd}\")\n",
        "print(f\"Final bias: ${bias_gd:.2f}\")\n",
        "print(f\"Final cost: ${cost_history[-1]:.2f}\")\n",
        "\n",
        "# Make predictions using gradient descent\n",
        "y_pred_gd_train = np.dot(X_train_scaled, theta_gd) + bias_gd\n",
        "y_pred_gd_test = np.dot(X_test_scaled, theta_gd) + bias_gd\n",
        "\n",
        "# Calculate metrics for gradient descent\n",
        "mse_gd_test = mean_squared_error(y_test, y_pred_gd_test)\n",
        "r2_gd_test = r2_score(y_test, y_pred_gd_test)\n",
        "mae_gd_test = mean_absolute_error(y_test, y_pred_gd_test)\n",
        "\n",
        "print(f\"\\nGradient Descent Performance:\")\n",
        "print(f\"Test MSE: ${mse_gd_test:.2f}\")\n",
        "print(f\"Test R²: {r2_gd_test:.4f}\")\n",
        "print(f\"Test MAE: ${mae_gd_test:.2f}\")\n",
        "\n",
        "# Compare with sklearn\n",
        "print(f\"\\nComparison with Sklearn:\")\n",
        "print(f\"Sklearn - MSE: ${mse_test:.2f}, R²: {r2_test:.4f}\")\n",
        "print(f\"Gradient Descent - MSE: ${mse_gd_test:.2f}, R²: {r2_gd_test:.4f}\")\n",
        "print(f\"Difference - MSE: ${abs(mse_test - mse_gd_test):.2f}, R²: {abs(r2_test - r2_gd_test):.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 6: Classification Metrics Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Classification Metrics Analysis\n",
        "print(\"CLASSIFICATION METRICS ANALYSIS\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "# Convert continuous predictions to binary classifications for analysis\n",
        "# Using median charges as threshold for high vs low insurance costs\n",
        "threshold = y_test.median()\n",
        "print(f\"Classification threshold (median charges): ${threshold:.2f}\")\n",
        "\n",
        "# Convert actual charges to binary\n",
        "y_test_binary = (y_test >= threshold).astype(int)\n",
        "y_pred_binary = (y_pred_test >= threshold).astype(int)\n",
        "y_pred_gd_binary = (y_pred_gd_test >= threshold).astype(int)\n",
        "\n",
        "print(f\"Class distribution in test set:\")\n",
        "print(f\"Low charges (0): {(y_test_binary == 0).sum()} samples\")\n",
        "print(f\"High charges (1): {(y_test_binary == 1).sum()} samples\")\n",
        "\n",
        "# Calculate classification metrics for sklearn model\n",
        "accuracy_sklearn = accuracy_score(y_test_binary, y_pred_binary)\n",
        "precision_sklearn = precision_score(y_test_binary, y_pred_binary)\n",
        "recall_sklearn = recall_score(y_test_binary, y_pred_binary)\n",
        "f1_sklearn = f1_score(y_test_binary, y_pred_binary)\n",
        "\n",
        "# Calculate classification metrics for gradient descent model\n",
        "accuracy_gd = accuracy_score(y_test_binary, y_pred_gd_binary)\n",
        "precision_gd = precision_score(y_test_binary, y_pred_gd_binary)\n",
        "recall_gd = recall_score(y_test_binary, y_pred_gd_binary)\n",
        "f1_gd = f1_score(y_test_binary, y_pred_gd_binary)\n",
        "\n",
        "print(f\"\\nSklearn Model Classification Metrics:\")\n",
        "print(f\"Accuracy: {accuracy_sklearn:.4f}\")\n",
        "print(f\"Precision: {precision_sklearn:.4f}\")\n",
        "print(f\"Recall: {recall_sklearn:.4f}\")\n",
        "print(f\"F1 Score: {f1_sklearn:.4f}\")\n",
        "\n",
        "print(f\"\\nGradient Descent Model Classification Metrics:\")\n",
        "print(f\"Accuracy: {accuracy_gd:.4f}\")\n",
        "print(f\"Precision: {precision_gd:.4f}\")\n",
        "print(f\"Recall: {recall_gd:.4f}\")\n",
        "print(f\"F1 Score: {f1_gd:.4f}\")\n",
        "\n",
        "# Confusion matrices\n",
        "cm_sklearn = confusion_matrix(y_test_binary, y_pred_binary)\n",
        "cm_gd = confusion_matrix(y_test_binary, y_pred_gd_binary)\n",
        "\n",
        "print(f\"\\nSklearn Confusion Matrix:\")\n",
        "print(f\"True Negatives: {cm_sklearn[0,0]}\")\n",
        "print(f\"False Positives: {cm_sklearn[0,1]}\")\n",
        "print(f\"False Negatives: {cm_sklearn[1,0]}\")\n",
        "print(f\"True Positives: {cm_sklearn[1,1]}\")\n",
        "\n",
        "print(f\"\\nGradient Descent Confusion Matrix:\")\n",
        "print(f\"True Negatives: {cm_gd[0,0]}\")\n",
        "print(f\"False Positives: {cm_gd[0,1]}\")\n",
        "print(f\"False Negatives: {cm_gd[1,0]}\")\n",
        "print(f\"True Positives: {cm_gd[1,1]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 7: Comprehensive Visualization and Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Comprehensive Visualization Dashboard\n",
        "fig = plt.figure(figsize=(24, 20))\n",
        "\n",
        "# 1. Cost function over epochs (Gradient Descent)\n",
        "plt.subplot(4, 5, 1)\n",
        "plt.plot(range(epochs), cost_history, color='blue', linewidth=2)\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Cost (MSE)')\n",
        "plt.title('Gradient Descent: Cost Function')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# 2. Actual vs Predicted (Sklearn)\n",
        "plt.subplot(4, 5, 2)\n",
        "plt.scatter(y_test, y_pred_test, color='purple', alpha=0.6)\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', linewidth=2)\n",
        "plt.xlabel('Actual Charges ($)')\n",
        "plt.ylabel('Predicted Charges ($)')\n",
        "plt.title('Sklearn: Actual vs Predicted')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# 3. Actual vs Predicted (Gradient Descent)\n",
        "plt.subplot(4, 5, 3)\n",
        "plt.scatter(y_test, y_pred_gd_test, color='green', alpha=0.6)\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', linewidth=2)\n",
        "plt.xlabel('Actual Charges ($)')\n",
        "plt.ylabel('Predicted Charges ($)')\n",
        "plt.title('Gradient Descent: Actual vs Predicted')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# 4. Residuals (Sklearn)\n",
        "plt.subplot(4, 5, 4)\n",
        "residuals_sklearn = y_test - y_pred_test\n",
        "plt.scatter(y_pred_test, residuals_sklearn, alpha=0.6, color='purple')\n",
        "plt.axhline(y=0, color='red', linestyle='--')\n",
        "plt.xlabel('Predicted Values ($)')\n",
        "plt.ylabel('Residuals ($)')\n",
        "plt.title('Sklearn: Residuals vs Predicted')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# 5. Residuals (Gradient Descent)\n",
        "plt.subplot(4, 5, 5)\n",
        "residuals_gd = y_test - y_pred_gd_test\n",
        "plt.scatter(y_pred_gd_test, residuals_gd, alpha=0.6, color='green')\n",
        "plt.axhline(y=0, color='red', linestyle='--')\n",
        "plt.xlabel('Predicted Values ($)')\n",
        "plt.ylabel('Residuals ($)')\n",
        "plt.title('Gradient Descent: Residuals vs Predicted')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# 6. Feature Importance (Sklearn)\n",
        "plt.subplot(4, 5, 6)\n",
        "feature_importance_sklearn = feature_importance.sort_values('Coefficient', key=abs, ascending=True)\n",
        "colors = ['red' if x < 0 else 'blue' for x in feature_importance_sklearn['Coefficient']]\n",
        "bars = plt.barh(feature_importance_sklearn['Feature'], feature_importance_sklearn['Coefficient'], color=colors, alpha=0.7)\n",
        "plt.xlabel('Coefficient Value')\n",
        "plt.title('Sklearn: Feature Importance')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# 7. Feature Importance (Gradient Descent)\n",
        "plt.subplot(4, 5, 7)\n",
        "feature_importance_gd = pd.DataFrame({\n",
        "    'Feature': feature_cols,\n",
        "    'Coefficient': theta_gd\n",
        "}).sort_values('Coefficient', key=abs, ascending=True)\n",
        "colors = ['red' if x < 0 else 'blue' for x in feature_importance_gd['Coefficient']]\n",
        "bars = plt.barh(feature_importance_gd['Feature'], feature_importance_gd['Coefficient'], color=colors, alpha=0.7)\n",
        "plt.xlabel('Coefficient Value')\n",
        "plt.title('Gradient Descent: Feature Importance')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# 8. Confusion Matrix (Sklearn)\n",
        "plt.subplot(4, 5, 8)\n",
        "sns.heatmap(cm_sklearn, annot=True, fmt='d', cmap='Blues', \n",
        "            xticklabels=['Predicted Low', 'Predicted High'],\n",
        "            yticklabels=['Actual Low', 'Actual High'])\n",
        "plt.title('Sklearn: Confusion Matrix')\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "\n",
        "# 9. Confusion Matrix (Gradient Descent)\n",
        "plt.subplot(4, 5, 9)\n",
        "sns.heatmap(cm_gd, annot=True, fmt='d', cmap='Greens', \n",
        "            xticklabels=['Predicted Low', 'Predicted High'],\n",
        "            yticklabels=['Actual Low', 'Actual High'])\n",
        "plt.title('Gradient Descent: Confusion Matrix')\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "\n",
        "# 10. Classification Metrics Comparison\n",
        "plt.subplot(4, 5, 10)\n",
        "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
        "sklearn_values = [accuracy_sklearn, precision_sklearn, recall_sklearn, f1_sklearn]\n",
        "gd_values = [accuracy_gd, precision_gd, recall_gd, f1_gd]\n",
        "\n",
        "x = np.arange(len(metrics))\n",
        "width = 0.35\n",
        "\n",
        "plt.bar(x - width/2, sklearn_values, width, label='Sklearn', alpha=0.7, color='purple')\n",
        "plt.bar(x + width/2, gd_values, width, label='Gradient Descent', alpha=0.7, color='green')\n",
        "\n",
        "plt.xlabel('Metrics')\n",
        "plt.ylabel('Score')\n",
        "plt.title('Classification Metrics Comparison')\n",
        "plt.xticks(x, metrics, rotation=45)\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# 11. ROC Curve (Sklearn)\n",
        "plt.subplot(4, 5, 11)\n",
        "fpr_sklearn, tpr_sklearn, _ = roc_curve(y_test_binary, y_pred_test)\n",
        "roc_auc_sklearn = auc(fpr_sklearn, tpr_sklearn)\n",
        "plt.plot(fpr_sklearn, tpr_sklearn, color='purple', lw=2, label=f'Sklearn (AUC = {roc_auc_sklearn:.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Sklearn: ROC Curve')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# 12. ROC Curve (Gradient Descent)\n",
        "plt.subplot(4, 5, 12)\n",
        "fpr_gd, tpr_gd, _ = roc_curve(y_test_binary, y_pred_gd_test)\n",
        "roc_auc_gd = auc(fpr_gd, tpr_gd)\n",
        "plt.plot(fpr_gd, tpr_gd, color='green', lw=2, label=f'Gradient Descent (AUC = {roc_auc_gd:.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Gradient Descent: ROC Curve')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# 13. Prediction Distribution Comparison\n",
        "plt.subplot(4, 5, 13)\n",
        "plt.hist(y_pred_test, bins=30, alpha=0.7, color='purple', label='Sklearn', density=True)\n",
        "plt.hist(y_pred_gd_test, bins=30, alpha=0.7, color='green', label='Gradient Descent', density=True)\n",
        "plt.axvline(x=threshold, color='red', linestyle='--', linewidth=2, label=f'Threshold (${threshold:.0f})')\n",
        "plt.xlabel('Predicted Charges ($)')\n",
        "plt.ylabel('Density')\n",
        "plt.title('Prediction Distribution Comparison')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# 14. Error Analysis\n",
        "plt.subplot(4, 5, 14)\n",
        "errors_sklearn = np.abs(y_test - y_pred_test)\n",
        "errors_gd = np.abs(y_test - y_pred_gd_test)\n",
        "plt.scatter(y_pred_test, errors_sklearn, alpha=0.6, color='purple', label='Sklearn')\n",
        "plt.scatter(y_pred_gd_test, errors_gd, alpha=0.6, color='green', label='Gradient Descent')\n",
        "plt.xlabel('Predicted Value ($)')\n",
        "plt.ylabel('Absolute Error ($)')\n",
        "plt.title('Error Analysis')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# 15. Model Performance Comparison\n",
        "plt.subplot(4, 5, 15)\n",
        "regression_metrics = ['MSE', 'R²', 'MAE', 'RMSE']\n",
        "sklearn_reg_values = [mse_test, r2_test, mae_test, rmse_test]\n",
        "gd_reg_values = [mse_gd_test, r2_gd_test, mae_gd_test, np.sqrt(mse_gd_test)]\n",
        "\n",
        "x = np.arange(len(regression_metrics))\n",
        "width = 0.35\n",
        "\n",
        "plt.bar(x - width/2, sklearn_reg_values, width, label='Sklearn', alpha=0.7, color='purple')\n",
        "plt.bar(x + width/2, gd_reg_values, width, label='Gradient Descent', alpha=0.7, color='green')\n",
        "\n",
        "plt.xlabel('Metrics')\n",
        "plt.ylabel('Value')\n",
        "plt.title('Regression Metrics Comparison')\n",
        "plt.xticks(x, regression_metrics, rotation=45)\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# 16. Learning Curve (Cost vs Iterations)\n",
        "plt.subplot(4, 5, 16)\n",
        "plt.plot(range(100, epochs), cost_history[100:], color='blue', linewidth=2)\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Cost (MSE)')\n",
        "plt.title('Learning Curve (Epochs 100-1000)')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# 17. Cost Convergence\n",
        "plt.subplot(4, 5, 17)\n",
        "cost_diff = np.diff(cost_history)\n",
        "plt.plot(range(1, len(cost_diff)+1), cost_diff, color='orange', linewidth=2)\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Cost Change')\n",
        "plt.title('Cost Convergence Rate')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# 18. Residuals Distribution (Sklearn)\n",
        "plt.subplot(4, 5, 18)\n",
        "plt.hist(residuals_sklearn, bins=30, alpha=0.7, color='purple', edgecolor='black')\n",
        "plt.xlabel('Residuals ($)')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Sklearn: Residuals Distribution')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# 19. Residuals Distribution (Gradient Descent)\n",
        "plt.subplot(4, 5, 19)\n",
        "plt.hist(residuals_gd, bins=30, alpha=0.7, color='green', edgecolor='black')\n",
        "plt.xlabel('Residuals ($)')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Gradient Descent: Residuals Distribution')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# 20. Model Comparison Summary\n",
        "plt.subplot(4, 5, 20)\n",
        "comparison_data = {\n",
        "    'Model': ['Sklearn', 'Gradient Descent'],\n",
        "    'MSE': [mse_test, mse_gd_test],\n",
        "    'R²': [r2_test, r2_gd_test],\n",
        "    'MAE': [mae_test, mae_gd_test],\n",
        "    'Accuracy': [accuracy_sklearn, accuracy_gd]\n",
        "}\n",
        "\n",
        "# Create a simple comparison table\n",
        "plt.text(0.1, 0.8, 'Model Performance Summary', fontsize=12, fontweight='bold', transform=plt.gca().transAxes)\n",
        "plt.text(0.1, 0.7, f'Sklearn MSE: ${mse_test:.2f}', fontsize=10, transform=plt.gca().transAxes)\n",
        "plt.text(0.1, 0.6, f'Sklearn R²: {r2_test:.4f}', fontsize=10, transform=plt.gca().transAxes)\n",
        "plt.text(0.1, 0.5, f'GD MSE: ${mse_gd_test:.2f}', fontsize=10, transform=plt.gca().transAxes)\n",
        "plt.text(0.1, 0.4, f'GD R²: {r2_gd_test:.4f}', fontsize=10, transform=plt.gca().transAxes)\n",
        "plt.text(0.1, 0.3, f'Sklearn Acc: {accuracy_sklearn:.4f}', fontsize=10, transform=plt.gca().transAxes)\n",
        "plt.text(0.1, 0.2, f'GD Acc: {accuracy_gd:.4f}', fontsize=10, transform=plt.gca().transAxes)\n",
        "plt.axis('off')\n",
        "plt.title('Performance Summary')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Final Summary\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"FINAL LAB 03 ANALYSIS SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Dataset: Insurance charges prediction\")\n",
        "print(f\"Total samples: {len(df)}\")\n",
        "print(f\"Samples after preprocessing: {len(df_clean)}\")\n",
        "print(f\"Features used: {len(feature_cols)}\")\n",
        "print(f\"Training samples: {len(X_train)}\")\n",
        "print(f\"Test samples: {len(X_test)}\")\n",
        "\n",
        "print(f\"\\nSKLEARN MODEL PERFORMANCE:\")\n",
        "print(f\"  Regression - MSE: ${mse_test:.2f}, R²: {r2_test:.4f}, MAE: ${mae_test:.2f}\")\n",
        "print(f\"  Classification - Accuracy: {accuracy_sklearn:.4f}, F1: {f1_sklearn:.4f}\")\n",
        "\n",
        "print(f\"\\nGRADIENT DESCENT MODEL PERFORMANCE:\")\n",
        "print(f\"  Regression - MSE: ${mse_gd_test:.2f}, R²: {r2_gd_test:.4f}, MAE: ${mae_gd_test:.2f}\")\n",
        "print(f\"  Classification - Accuracy: {accuracy_gd:.4f}, F1: {f1_gd:.4f}\")\n",
        "\n",
        "print(f\"\\nKEY INSIGHTS:\")\n",
        "print(f\"  • Smoking status is the most important predictor of insurance charges\")\n",
        "print(f\"  • Age and BMI also significantly impact insurance costs\")\n",
        "print(f\"  • Both models show similar performance, validating gradient descent implementation\")\n",
        "print(f\"  • The model can predict insurance charges with reasonable accuracy\")\n",
        "print(f\"  • Classification metrics help understand model performance for decision-making\")\n",
        "print(\"=\"*60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
